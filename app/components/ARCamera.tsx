'use client'

import { useRef, useEffect, useState, useCallback } from 'react'
import { useRouter } from 'next/navigation'
import Webcam from 'react-webcam'
import { motion, useAnimation, AnimatePresence } from 'framer-motion'
import type { FaceMesh as FaceMeshType, NormalizedLandmark } from '@mediapipe/face_mesh'

interface ARCameraProps {
  className?: string
  onComplete?: () => void // ë¶„ì„ ì™„ë£Œ ì‹œ ì½œë°± (ëª¨ë‹¬ ë‹«ê¸° ë“±)
  isReady?: boolean // ì¹´ë©”ë¼ ì´ˆê¸°í™” ì¤€ë¹„ ì™„ë£Œ ì—¬ë¶€ (Lazy Initialization)
}

// ğŸ¯ ì´ì›í™” ì „ëµ ìƒìˆ˜ (Dual Strategy Constants)
const TRACKING_CANVAS_WIDTH = 360 // íŠ¸ë˜í‚¹ìš© ì¶•ì†Œ ìº”ë²„ìŠ¤ ë„ˆë¹„ (ì„±ëŠ¥ ìµœì í™”)
const CAPTURE_WIDTH = 1920 // ìº¡ì²˜ìš© ê³ í•´ìƒë„ ë„ˆë¹„
const CAPTURE_HEIGHT = 1080 // ìº¡ì²˜ìš© ê³ í•´ìƒë„ ë†’ì´
const CAPTURE_QUALITY = 1.0 // ìº¡ì²˜ í’ˆì§ˆ (1.0 = ë¬´ì••ì¶•, ìµœê³  í™”ì§ˆ)

export default function ARCamera({ className = '', onComplete, isReady = true }: ARCameraProps) {
  const webcamRef = useRef<Webcam>(null)
  const canvasRef = useRef<HTMLCanvasElement>(null)
  const trackingCanvasRef = useRef<HTMLCanvasElement | null>(null) // ğŸš€ íŠ¸ë˜í‚¹ìš© ì¶•ì†Œ ìº”ë²„ìŠ¤ (MediaPipe ì—°ì‚°ìš©)
  const faceMeshRef = useRef<FaceMeshType | null>(null)
  const animationFrameRef = useRef<number | null>(null)
  const scanLineYRef = useRef<number>(0)
  const scanDirectionRef = useRef<number>(1) // 1: ì•„ë˜ë¡œ, -1: ìœ„ë¡œ
  const [isModelReady, setIsModelReady] = useState(false)
  const [cameraError, setCameraError] = useState<string | null>(null)
  const [isCameraReady, setIsCameraReady] = useState(false)
  const [isCameraLoading, setIsCameraLoading] = useState(true)
  const [isMockMode, setIsMockMode] = useState(false)
  const [scanningStage, setScanningStage] = useState<'idle' | 'scanning' | 'processing' | 'complete'>('idle')
  const [bottomMessage, setBottomMessage] = useState('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
  const [isShutterDisabled, setIsShutterDisabled] = useState(true)
  const [frozenFrame, setFrozenFrame] = useState<string | null>(null) // ğŸ“¸ ì •ì§€ í”„ë ˆì„ ì´ë¯¸ì§€
  const [laserProgress, setLaserProgress] = useState(0) // ë ˆì´ì € ì§„í–‰ë¥  (0-100) - Mesh Revealìš©
  const [showDataTransfer, setShowDataTransfer] = useState(false) // ë°ì´í„° ì „ì†¡ ì—°ì¶œ ìƒíƒœ
  const router = useRouter()
  const laserControls = useAnimation() // ë ˆì´ì € ë°” ì• ë‹ˆë©”ì´ì…˜ ì»¨íŠ¸ë¡¤
  const faceMeshControls = useAnimation() // ì–¼êµ´ ë©”ì‰¬ í„ìŠ¤ ì• ë‹ˆë©”ì´ì…˜ ì»¨íŠ¸ë¡¤
  const fadeControls = useAnimation() // í˜ì´ë“œ ì•„ì›ƒ ì• ë‹ˆë©”ì´ì…˜ ì»¨íŠ¸ë¡¤
  const rippleControls = useAnimation() // ì›í˜• íŒŒë™ ì• ë‹ˆë©”ì´ì…˜ ì»¨íŠ¸ë¡¤
  const landmarksRef = useRef<any[] | null>(null) // ëœë“œë§ˆí¬ ì €ì¥ìš©
  const [isFaceDetected, setIsFaceDetected] = useState(false) // ì–¼êµ´ ê°ì§€ ìƒíƒœ
  const [faceDetectionStartTime, setFaceDetectionStartTime] = useState<number | null>(null) // ì–¼êµ´ ê°ì§€ ì‹œì‘ ì‹œê°„
  const faceDetectionDurationRef = useRef<number>(0) // ì–¼êµ´ ê°ì§€ ì§€ì† ì‹œê°„ (ms)
  const [faceAlignment, setFaceAlignment] = useState<'none' | 'aligned'>('none') // ì–¼êµ´ ì •ë ¬ ìƒíƒœ
  const faceAlignmentStartTimeRef = useRef<number | null>(null) // ì–¼êµ´ ì •ë ¬ ì‹œì‘ ì‹œê°„
  const [guideMessage, setGuideMessage] = useState('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”') // ì‹¤ì‹œê°„ ê°€ì´ë“œ ë©”ì‹œì§€
  const [guideColor, setGuideColor] = useState<'white' | 'yellow' | 'mint'>('white') // ê°€ì´ë“œë¼ì¸ ìƒ‰ìƒ
  const [lightingStatus, setLightingStatus] = useState<'ok' | 'too-dark'>('ok') // ì¡°ëª… ìƒíƒœ
  const [poseStatus, setPoseStatus] = useState<'ok' | 'not-frontal'>('ok') // ì–¼êµ´ ê°ë„ ìƒíƒœ
  const lastLightingCheckRef = useRef<number>(0) // ë§ˆì§€ë§‰ ì¡°ëª… ê²€ì‚¬ ì‹œê°„ (ì„±ëŠ¥ ìµœì í™”)
  const [isScreenLightOn, setIsScreenLightOn] = useState(false) // í™”ë©´ ì¡°ëª… ìƒíƒœ
  
  // ğŸ¯ í•¸ì¦ˆí”„ë¦¬ ì˜¤í†  ìº¡ì²˜ ìƒíƒœ
  const lockOnStartTimeRef = useRef<number | null>(null) // ë½ì˜¨ ì‹œì‘ ì‹œê°„
  const [lockOnProgress, setLockOnProgress] = useState(0) // ë½ì˜¨ ì§„í–‰ë¥  (0-100)
  const [countdownText, setCountdownText] = useState<string | null>(null) // ì¹´ìš´íŠ¸ë‹¤ìš´ í…ìŠ¤íŠ¸
  const autoCaptureTriggeredRef = useRef(false) // ì˜¤í†  ìº¡ì²˜ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
  const executeCinematicSequenceRef = useRef<(() => void) | null>(null) // ì‹œë„¤ë§ˆí‹± ì‹œí€€ìŠ¤ í•¨ìˆ˜ ref
  const isCleanedUpRef = useRef(false) // ğŸ§¹ ë©”ëª¨ë¦¬ cleanup ìƒíƒœ ì¶”ì 

  // ğŸ§¹ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€: ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì „ì²´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  useEffect(() => {
    isCleanedUpRef.current = false

    return () => {
      console.log('ğŸ§¹ [ARCamera] Cleanup: Releasing all resources...')
      isCleanedUpRef.current = true

      // 1. Animation Frame ì·¨ì†Œ
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
        animationFrameRef.current = null
        console.log('ğŸ§¹ [ARCamera] Animation frame cancelled')
      }

      // 2. FaceMesh ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ
      if (faceMeshRef.current) {
        try {
          faceMeshRef.current.close()
          faceMeshRef.current = null
          console.log('ğŸ§¹ [ARCamera] FaceMesh instance closed')
        } catch (error) {
          console.warn('ğŸ§¹ [ARCamera] Error closing FaceMesh:', error)
        }
      }

      // 3. ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ (ëª¨ë“  íŠ¸ë™ stop)
      if (webcamRef.current?.video?.srcObject) {
        try {
          const stream = webcamRef.current.video.srcObject as MediaStream
          stream.getTracks().forEach((track) => {
            track.stop()
            console.log(`ğŸ§¹ [ARCamera] Camera track stopped: ${track.kind}`)
          })
          webcamRef.current.video.srcObject = null
          console.log('ğŸ§¹ [ARCamera] Camera stream released')
        } catch (error) {
          console.warn('ğŸ§¹ [ARCamera] Error stopping camera stream:', error)
        }
      }

      // 4. Canvas ì •ë¦¬
      if (canvasRef.current) {
        const ctx = canvasRef.current.getContext('2d')
        if (ctx) {
          ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height)
        }
        console.log('ğŸ§¹ [ARCamera] Canvas cleared')
      }

      // 4-1. ğŸš€ íŠ¸ë˜í‚¹ìš© ì¶•ì†Œ ìº”ë²„ìŠ¤ ì •ë¦¬
      if (trackingCanvasRef.current) {
        trackingCanvasRef.current = null
        console.log('ğŸ§¹ [ARCamera] Tracking canvas released')
      }

      // 5. ëœë“œë§ˆí¬ ì°¸ì¡° ì •ë¦¬
      landmarksRef.current = null

      // 6. ê¸°íƒ€ ref ì •ë¦¬
      lockOnStartTimeRef.current = null
      executeCinematicSequenceRef.current = null
      faceAlignmentStartTimeRef.current = null

      console.log('ğŸ§¹ [ARCamera] Cleanup complete!')
    }
  }, [])

  // FaceMesh ì´ˆê¸°í™” (isReadyê°€ trueì¼ ë•Œë§Œ)
  useEffect(() => {
    // ğŸš€ Lazy Initialization: isReadyê°€ falseë©´ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ
    if (!isReady) {
      return
    }

    let isMounted = true

    const initFaceMesh = async () => {
      try {
        // ë™ì  importë¡œ MediaPipe ë¡œë“œ
        const { FaceMesh } = await import('@mediapipe/face_mesh')

        if (!isMounted) return

        const faceMesh = new FaceMesh({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
          },
        })

        faceMesh.setOptions({
          maxNumFaces: 1,
          refineLandmarks: true,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5,
        })

        faceMesh.onResults((results) => {
          const canvas = canvasRef.current
          const video = webcamRef.current?.video
          const currentMockMode = isMockMode // í´ë¡œì € ë¬¸ì œ í•´ê²°

          if (!canvas) return

          const ctx = canvas.getContext('2d')
          if (!ctx) return

          // Mock ëª¨ë“œì¼ ê²½ìš° ì´ë¯¸ì§€ í¬ê¸° ì‚¬ìš©, ì‹¤ì œ ëª¨ë“œì¼ ê²½ìš° ë¹„ë””ì˜¤ í¬ê¸° ì‚¬ìš©
          let canvasWidth = 640
          let canvasHeight = 480
          
          if (currentMockMode) {
            // Mock ëª¨ë“œ: ì´ë¯¸ì§€ ìš”ì†Œì—ì„œ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
            if (mockImg && mockImg.complete) {
              canvasWidth = mockImg.naturalWidth || 640
              canvasHeight = mockImg.naturalHeight || 480
            }
          } else if (video) {
            canvasWidth = video.videoWidth
            canvasHeight = video.videoHeight
          } else {
            return
          }

          // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
          canvas.width = canvasWidth
          canvas.height = canvasHeight

          // ìº”ë²„ìŠ¤ ì´ˆê¸°í™”
          ctx.clearRect(0, 0, canvas.width, canvas.height)

          // ì–¼êµ´ ê°ì§€ ë° ì •ë ¬ ê²€ì¦
          let faceDetected = false
          let faceAligned = false

          if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
            const landmarks = results.multiFaceLandmarks[0]
            
            // ì–¼êµ´ í¬ê¸° ê³„ì‚° (í™”ë©´ ëŒ€ë¹„ ë¹„ìœ¨)
            const faceBounds = calculateFaceBounds(landmarks, canvas.width, canvas.height)
            const faceArea = faceBounds.width * faceBounds.height
            const screenArea = canvas.width * canvas.height
            const faceAreaRatio = faceArea / screenArea
            
            // ì–¼êµ´ì´ í™”ë©´ì˜ 20% ì´ìƒ ì°¨ì§€í•´ì•¼ ìœ íš¨
            const faceSizeValid = faceAreaRatio >= 0.2
            faceDetected = faceSizeValid

            if (faceDetected) {
              // Mock ëª¨ë“œì¼ ê²½ìš° í•­ìƒ ì •ë ¬ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼, ì‹¤ì œ ëª¨ë“œì¼ ê²½ìš° ê²€ì‚¬
              if (currentMockMode) {
                faceAligned = true
                setLightingStatus('ok')
                setPoseStatus('ok')
                setGuideMessage('âœ¨ ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš”')
                setGuideColor('mint')
              } else {
                // ì–¼êµ´ ì •ë ¬ ê²€ì‚¬ ë° ì‹¤ì‹œê°„ í”¼ë“œë°± (3ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ)
                const video = webcamRef.current?.video || null
                const alignmentResult = checkFaceAlignmentWithFeedback(landmarks, canvas.width, canvas.height, faceBounds, video)
                faceAligned = alignmentResult.aligned
                // guideMessageì™€ guideColorëŠ” checkFaceAlignmentWithFeedback ë‚´ë¶€ì—ì„œ ì„¤ì •ë¨
              }
              
              landmarksRef.current = landmarks // ëœë“œë§ˆí¬ ì €ì¥
              drawFaceTessellation(ctx, landmarks, canvas.width, canvas.height)
              drawProblemArea(ctx, landmarks, canvas.width, canvas.height)
              
              // ì–¼êµ´ ê°ì§€ ì‹œì‘ ì‹œê°„ ê¸°ë¡
              const now = Date.now()
              if (faceDetectionStartTime === null) {
                setFaceDetectionStartTime(now)
                faceDetectionDurationRef.current = 0
              } else {
                // ì–¼êµ´ ê°ì§€ ì§€ì† ì‹œê°„ ì—…ë°ì´íŠ¸
                faceDetectionDurationRef.current = now - faceDetectionStartTime
              }

              // ì–¼êµ´ ì •ë ¬ ìƒíƒœ ì—…ë°ì´íŠ¸
              if (faceAligned) {
                if (faceAlignmentStartTimeRef.current === null) {
                  faceAlignmentStartTimeRef.current = now
                }
                setFaceAlignment('aligned')
              } else {
                faceAlignmentStartTimeRef.current = null
                setFaceAlignment('none')
              }
            } else {
              // ì–¼êµ´ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ê°ì§€ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
              if (!currentMockMode) {
                setFaceDetectionStartTime(null)
                faceDetectionDurationRef.current = 0
                faceAlignmentStartTimeRef.current = null
                setFaceAlignment('none')
                setLightingStatus('ok')
                setPoseStatus('ok')
                setGuideMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
                setGuideColor('white')
              }
            }

            // ì–¼êµ´ ê°ì§€ ìƒíƒœ ì—…ë°ì´íŠ¸
            setIsFaceDetected(faceDetected)
          } else {
            // ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ
            if (!currentMockMode) {
              setIsFaceDetected(false)
              setFaceDetectionStartTime(null)
              faceDetectionDurationRef.current = 0
              faceAlignmentStartTimeRef.current = null
              setFaceAlignment('none')
              setLightingStatus('ok')
              setPoseStatus('ok')
              setGuideMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
              setGuideColor('white')
            } else {
              // Mock ëª¨ë“œ: ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•„ë„ ì •ë ¬ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬ (ì´ë¯¸ì§€ ë¶„ì„ì€ ê³„ì† ì§„í–‰)
              setIsFaceDetected(true)
              setFaceAlignment('aligned')
              const now = Date.now()
              if (faceAlignmentStartTimeRef.current === null) {
                faceAlignmentStartTimeRef.current = now
              }
            }
          }

          // ìŠ¤ìº” ë¼ì¸ ì• ë‹ˆë©”ì´ì…˜
          drawScanLine(ctx, canvas.width, canvas.height)
        })

        faceMeshRef.current = faceMesh
        setIsModelReady(true)
      } catch (error) {
        console.error('Failed to initialize FaceMesh:', error)
      }
    }

    initFaceMesh()

    return () => {
      console.log('ğŸ§¹ [ARCamera] FaceMesh useEffect cleanup triggered')
      isMounted = false
      
      // Animation frame ì·¨ì†Œ
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current)
        animationFrameRef.current = null
      }
      
      // FaceMesh ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ (ë©”ì¸ cleanupì—ì„œ ì¤‘ë³µ ì²´í¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œë„ ì²˜ë¦¬)
      if (faceMeshRef.current && !isCleanedUpRef.current) {
        try {
          faceMeshRef.current.close()
          faceMeshRef.current = null
          console.log('ğŸ§¹ [ARCamera] FaceMesh closed in useEffect cleanup')
        } catch (error) {
          console.warn('ğŸ§¹ [ARCamera] Error in FaceMesh cleanup:', error)
        }
      }
      
      // ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ ë¦¬ì…‹
      setIsModelReady(false)
    }
  }, [isReady]) // isReadyê°€ trueë¡œ ë³€ê²½ë˜ë©´ ì´ˆê¸°í™” ì‹¤í–‰

  // ì–¼êµ´ ê²½ê³„ ê³„ì‚° (ë„ˆë¹„, ë†’ì´, ì¤‘ì‹¬ì )
  const calculateFaceBounds = (
    landmarks: NormalizedLandmark[],
    width: number,
    height: number
  ): { x: number; y: number; width: number; height: number; centerX: number; centerY: number } => {
    if (landmarks.length === 0) {
      return { x: 0, y: 0, width: 0, height: 0, centerX: 0, centerY: 0 }
    }

    let minX = Infinity
    let maxX = -Infinity
    let minY = Infinity
    let maxY = -Infinity

    landmarks.forEach((landmark) => {
      const x = landmark.x * width
      const y = landmark.y * height
      minX = Math.min(minX, x)
      maxX = Math.max(maxX, x)
      minY = Math.min(minY, y)
      maxY = Math.max(maxY, y)
    })

    return {
      x: minX,
      y: minY,
      width: maxX - minX,
      height: maxY - minY,
      centerX: (minX + maxX) / 2,
      centerY: (minY + maxY) / 2,
    }
  }

  // ì¡°ëª…(ë°ê¸°) ê°ì§€ í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™”: 500msë§ˆë‹¤ë§Œ ì‹¤í–‰)
  const checkLighting = (video: HTMLVideoElement | null, forceCheck: boolean = false): { ok: boolean; message: string } => {
    if (!video || video.readyState < video.HAVE_METADATA) {
      return { ok: true, message: '' } // ë¹„ë””ì˜¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´ í†µê³¼
    }

    // í™”ë©´ ì¡°ëª…ì´ ì¼œì ¸ ìˆìœ¼ë©´ ì¡°ëª… ê²€ì‚¬ í†µê³¼
    if (isScreenLightOn) {
      return { ok: true, message: '' }
    }

    // ì„±ëŠ¥ ìµœì í™”: 500msë§ˆë‹¤ë§Œ ì¡°ëª… ê²€ì‚¬ ì‹¤í–‰ (ê°•ì œ ê²€ì‚¬ê°€ ì•„ë‹Œ ê²½ìš°)
    const now = Date.now()
    if (!forceCheck && now - lastLightingCheckRef.current < 500) {
      // ë§ˆì§€ë§‰ ê²€ì‚¬ ê²°ê³¼ë¥¼ ë°˜í™˜ (ìƒíƒœëŠ” ì´ë¯¸ ì—…ë°ì´íŠ¸ë¨)
      return lightingStatus === 'ok' 
        ? { ok: true, message: '' } 
        : { ok: false, message: 'ğŸš« ë„ˆë¬´ ì–´ë‘ì›Œìš”! ë°ì€ ê³³ìœ¼ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.' }
    }
    lastLightingCheckRef.current = now

    try {
      const canvas = document.createElement('canvas')
      canvas.width = video.videoWidth
      canvas.height = video.videoHeight
      const ctx = canvas.getContext('2d')
      if (!ctx) return { ok: true, message: '' }

      // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height)

      // ì¤‘ì•™ ì˜ì—­ ìƒ˜í”Œë§ (í™”ë©´ì˜ 30% x 30% ì˜ì—­)
      const sampleWidth = Math.floor(canvas.width * 0.3)
      const sampleHeight = Math.floor(canvas.height * 0.3)
      const startX = Math.floor((canvas.width - sampleWidth) / 2)
      const startY = Math.floor((canvas.height - sampleHeight) / 2)

      const imageData = ctx.getImageData(startX, startY, sampleWidth, sampleHeight)
      const data = imageData.data

      // í‰ê·  ë°ê¸° ê³„ì‚° (Luminance ê³µì‹: 0.299*R + 0.587*G + 0.114*B)
      let totalLuminance = 0
      let pixelCount = 0

      // ìƒ˜í”Œë§ ìµœì í™”: ëª¨ë“  í”½ì…€ì´ ì•„ë‹Œ 10í”½ì…€ë§ˆë‹¤ ìƒ˜í”Œë§
      for (let i = 0; i < data.length; i += 40) { // 4 * 10 = 40 (RGBA * 10)
        const r = data[i]
        const g = data[i + 1]
        const b = data[i + 2]
        const luminance = 0.299 * r + 0.587 * g + 0.114 * b
        totalLuminance += luminance
        pixelCount++
      }

      const avgLuminance = totalLuminance / pixelCount

      if (avgLuminance < 80) {
        return { ok: false, message: 'ğŸš« ë„ˆë¬´ ì–´ë‘ì›Œìš”! ë°ì€ ê³³ìœ¼ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.' }
      }

      return { ok: true, message: '' }
    } catch (error) {
      console.error('Lighting check error:', error)
      return { ok: true, message: '' } // ì—ëŸ¬ ë°œìƒ ì‹œ í†µê³¼
    }
  }

  // ì–¼êµ´ ê°ë„(Pose) ê°ì§€ í•¨ìˆ˜
  const checkFacePose = (landmarks: NormalizedLandmark[]): { ok: boolean; message: string } => {
    if (landmarks.length < 468) {
      return { ok: true, message: '' } // ëœë“œë§ˆí¬ê°€ ë¶€ì¡±í•˜ë©´ í†µê³¼
    }

    try {
      // MediaPipe Face Mesh ëœë“œë§ˆí¬ ì¸ë±ìŠ¤
      const NOSE_TIP = 1 // ì½”ë
      const LEFT_EAR = 234 // ì™¼ìª½ ê·€ (ëŒ€ëµ)
      const RIGHT_EAR = 454 // ì˜¤ë¥¸ìª½ ê·€ (ëŒ€ëµ)
      const CHIN = 18 // í„±
      const FOREHEAD = 10 // ì´ë§ˆ (ëŒ€ëµ)

      const noseTip = landmarks[NOSE_TIP]
      const leftEar = landmarks[LEFT_EAR]
      const rightEar = landmarks[RIGHT_EAR]
      const chin = landmarks[CHIN]
      const forehead = landmarks[FOREHEAD]

      // ì¢Œìš° íšŒì „(Yaw) ê²€ì‚¬: ì½”ëê³¼ ì–‘ìª½ ê·€ì˜ ê±°ë¦¬ ë¹„ìœ¨
      const distLeft = Math.sqrt(
        Math.pow(noseTip.x - leftEar.x, 2) + Math.pow(noseTip.y - leftEar.y, 2)
      )
      const distRight = Math.sqrt(
        Math.pow(noseTip.x - rightEar.x, 2) + Math.pow(noseTip.y - rightEar.y, 2)
      )

      // ê±°ë¦¬ ë¹„ìœ¨ì´ 1.3 ì´ìƒ ì°¨ì´ë‚˜ë©´ ì˜†ì„ ë³´ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ íŒì •
      const yawRatio = Math.max(distLeft, distRight) / Math.min(distLeft, distRight)
      if (yawRatio > 1.3) {
        return { ok: false, message: 'ğŸ‘€ ì •ë©´ì„ ì‘ì‹œí•´ì£¼ì„¸ìš”.' }
      }

      // ìƒí•˜ ê¸°ìš¸ê¸°(Pitch) ê²€ì‚¬: ì½”ì™€ í„±, ì´ë§ˆì˜ ê±°ë¦¬
      const distChin = Math.sqrt(
        Math.pow(noseTip.x - chin.x, 2) + Math.pow(noseTip.y - chin.y, 2)
      )
      const distForehead = Math.sqrt(
        Math.pow(noseTip.x - forehead.x, 2) + Math.pow(noseTip.y - forehead.y, 2)
      )

      // ì½”-í„± ê±°ë¦¬ì™€ ì½”-ì´ë§ˆ ê±°ë¦¬ì˜ ë¹„ìœ¨ì´ ë¹„ì •ìƒì ì´ë©´ ê¸°ìš¸ì–´ì§
      const pitchRatio = Math.max(distChin, distForehead) / Math.min(distChin, distForehead)
      if (pitchRatio > 1.5) {
        return { ok: false, message: 'ğŸ‘€ ì •ë©´ì„ ì‘ì‹œí•´ì£¼ì„¸ìš”.' }
      }

      return { ok: true, message: '' }
    } catch (error) {
      console.error('Pose check error:', error)
      return { ok: true, message: '' } // ì—ëŸ¬ ë°œìƒ ì‹œ í†µê³¼
    }
  }

  // ì–¼êµ´ ì •ë ¬ ê²€ì‚¬ ë° ì‹¤ì‹œê°„ í”¼ë“œë°± (Face ID ìŠ¤íƒ€ì¼ - ìƒì„¸í•œ í”¼ë“œë°± ì œê³µ)
  const checkFaceAlignmentWithFeedback = (
    landmarks: NormalizedLandmark[],
    screenWidth: number,
    screenHeight: number,
    faceBounds: { centerX: number; centerY: number; width: number; height: number },
    video: HTMLVideoElement | null
  ): { aligned: boolean; message: string; color: 'white' | 'yellow' | 'mint' } => {
    // ê°€ì´ë“œë¼ì¸ í¬ê¸° (í™”ë©´ ë„ˆë¹„ì˜ 70%, ë†’ì´ì˜ 55%) - ì–¼êµ´ ëª¨ì–‘ì— ë§ì¶˜ íƒ€ì›í˜•
    const guideWidth = screenWidth * 0.7
    const guideHeight = screenHeight * 0.55
    const guideCenterX = screenWidth / 2
    const guideCenterY = screenHeight * 0.4 // í™”ë©´ ì •ì¤‘ì•™ë³´ë‹¤ ì•½ê°„ ìœ„ìª½ (ëˆˆë†’ì´)

    // 3ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ ì²´í¬)

    // 1ë‹¨ê³„: ì¡°ëª…(ë°ê¸°) ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ 1ìœ„) - í™”ë©´ ì¡°ëª…ì´ ì¼œì ¸ ìˆìœ¼ë©´ í†µê³¼
    const lightingCheck = checkLighting(video)
    if (!lightingCheck.ok && !isScreenLightOn) {
      setLightingStatus('too-dark')
      setGuideMessage(lightingCheck.message)
      setGuideColor('yellow')
      return { aligned: false, message: lightingCheck.message, color: 'yellow' }
    }
    setLightingStatus('ok')

    // 2ë‹¨ê³„: ì–¼êµ´ ê°ë„(Pose) ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ 2ìœ„)
    const poseCheck = checkFacePose(landmarks)
    if (!poseCheck.ok) {
      setPoseStatus('not-frontal')
      setGuideMessage(poseCheck.message)
      setGuideColor('yellow')
      return { aligned: false, message: poseCheck.message, color: 'yellow' }
    }
    setPoseStatus('ok')

    // 3ë‹¨ê³„: ê±°ë¦¬ ë° ìœ„ì¹˜ ê²€ì‚¬ (ìš°ì„ ìˆœìœ„ 3ìœ„)
    const noseTipIndex = 1
    if (noseTipIndex >= landmarks.length) {
      setGuideMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
      setGuideColor('white')
      return { aligned: false, message: 'ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”', color: 'white' }
    }

    const noseTip = landmarks[noseTipIndex]
    const noseTipX = noseTip.x * screenWidth
    const noseTipY = noseTip.y * screenHeight

    // ìœ„ì¹˜ íŒë³„ (Centering) - ì½”ëì´ í™”ë©´ ì¤‘ì•™ì—ì„œ Â±10% ì˜¤ì°¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ”ì§€ ê²€ì‚¬
    const centerXDiff = Math.abs(noseTipX - guideCenterX)
    const centerYDiff = Math.abs(noseTipY - guideCenterY)
    const maxCenterDiffX = screenWidth * 0.1 // 10% í—ˆìš© ì˜¤ì°¨
    const maxCenterDiffY = screenHeight * 0.1 // 10% í—ˆìš© ì˜¤ì°¨

    const isCentered = centerXDiff <= maxCenterDiffX && centerYDiff <= maxCenterDiffY

    // ê±°ë¦¬ íŒë³„ (Distance) - ì–¼êµ´ ë„ˆë¹„ê°€ ê°€ì´ë“œë¼ì¸ ë„ˆë¹„ì˜ ë¹„ìœ¨
    const faceWidthRatio = faceBounds.width / guideWidth
    const faceHeightRatio = faceBounds.height / guideHeight
    const minFillRatio = 0.5 // 50% ë¯¸ë§Œì´ë©´ ë„ˆë¬´ ë©€ìŒ
    const maxFillRatio = 0.9 // 90% ì´ˆê³¼ë©´ ë„ˆë¬´ ê°€ê¹Œì›€
    const perfectMinRatio = 0.6 // ì™„ë²½í•œ ìƒíƒœì˜ ìµœì†Œ ë¹„ìœ¨
    const perfectMaxRatio = 0.85 // ì™„ë²½í•œ ìƒíƒœì˜ ìµœëŒ€ ë¹„ìœ¨

    // ìœ„ì¹˜ê°€ ë²—ì–´ë‚œ ê²½ìš°
    if (!isCentered) {
      setGuideMessage('ğŸ¯ ì–¼êµ´ì„ ì¤‘ì•™ìœ¼ë¡œ ì˜®ê²¨ì£¼ì„¸ìš”')
      setGuideColor('yellow')
      return { aligned: false, message: 'ğŸ¯ ì–¼êµ´ì„ ì¤‘ì•™ìœ¼ë¡œ ì˜®ê²¨ì£¼ì„¸ìš”', color: 'yellow' }
    }

    // ê±°ë¦¬ê°€ ë„ˆë¬´ ë¨¼ ê²½ìš°
    if (faceWidthRatio < minFillRatio) {
      setGuideMessage('ğŸ” ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ì˜¤ì„¸ìš”')
      setGuideColor('white')
      return { aligned: false, message: 'ğŸ” ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ì˜¤ì„¸ìš”', color: 'white' }
    }

    // ê±°ë¦¬ê°€ ë„ˆë¬´ ê°€ê¹Œìš´ ê²½ìš°
    if (faceWidthRatio > maxFillRatio) {
      setGuideMessage('âœ‹ ì¡°ê¸ˆë§Œ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”')
      setGuideColor('white')
      return { aligned: false, message: 'âœ‹ ì¡°ê¸ˆë§Œ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”', color: 'white' }
    }

    // ì™„ë²½í•œ ìƒíƒœ - ëª¨ë“  ì¡°ê±´ í†µê³¼ (ì¡°ëª…, ê°ë„, ê±°ë¦¬ ëª¨ë‘ OK)
    if (faceWidthRatio >= perfectMinRatio && faceWidthRatio <= perfectMaxRatio && 
        faceHeightRatio >= perfectMinRatio && faceHeightRatio <= perfectMaxRatio) {
      setGuideMessage('âœ¨ ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš”')
      setGuideColor('mint')
      return { aligned: true, message: 'âœ¨ ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš”', color: 'mint' }
    }

    // ì¤‘ê°„ ìƒíƒœ (50%~60% ë˜ëŠ” 85%~90%)
    if (faceWidthRatio < perfectMinRatio) {
      setGuideMessage('ğŸ” ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ì˜¤ì„¸ìš”')
      setGuideColor('white')
      return { aligned: false, message: 'ğŸ” ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ì˜¤ì„¸ìš”', color: 'white' }
    } else {
      setGuideMessage('âœ‹ ì¡°ê¸ˆë§Œ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”')
      setGuideColor('white')
      return { aligned: false, message: 'âœ‹ ì¡°ê¸ˆë§Œ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì„¸ìš”', color: 'white' }
    }
  }

  // ì–¼êµ´ ì •ë ¬ ê²€ì‚¬ (Face ID ìŠ¤íƒ€ì¼ - ì—„ê²©í•œ íŒì •) - ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ (í˜¸í™˜ì„±, ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
  const checkFaceAlignment = (
    landmarks: NormalizedLandmark[],
    screenWidth: number,
    screenHeight: number,
    faceBounds: { centerX: number; centerY: number; width: number; height: number }
  ): boolean => {
    // ì´ í•¨ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
    // checkFaceAlignmentWithFeedbackì„ ì§ì ‘ ì‚¬ìš©í•´ì•¼ í•¨
    return false
  }

  // ì–¼êµ´ ìœ¤ê³½ì„  (Tessellation) ê·¸ë¦¬ê¸°
  const drawFaceTessellation = (
    ctx: CanvasRenderingContext2D,
    landmarks: NormalizedLandmark[],
    width: number,
    height: number
  ) => {
    ctx.strokeStyle = 'rgba(255, 255, 255, 0.2)'
    ctx.lineWidth = 0.5
    ctx.beginPath()

    // MediaPipe FaceMesh Tessellation ì—°ê²° ì •ë³´
    // ì£¼ìš” ì–¼êµ´ ìœ¤ê³½ì„  í¬ì¸íŠ¸ë“¤ì„ ì—°ê²°
    const faceOutline = [
      10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109, 10
    ]

    // ì–¼êµ´ ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
    for (let i = 0; i < faceOutline.length; i++) {
      const idx = faceOutline[i]
      if (idx < landmarks.length) {
        const x = landmarks[idx].x * width
        const y = landmarks[idx].y * height

        if (i === 0) {
          ctx.moveTo(x, y)
        } else {
          ctx.lineTo(x, y)
        }
      }
    }
    ctx.closePath()
    ctx.stroke()

    // ì¶”ê°€ ì–¼êµ´ ë©”ì‰¬ ì—°ê²°ì„  (ë” ì„¸ë°€í•œ tessellation)
    const connections = [
      // ëˆˆ ì£¼ë³€
      [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246],
      [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398],
      // ì… ì£¼ë³€
      [61, 146, 91, 181, 84, 17, 314, 405, 320, 307, 375, 321, 308, 324, 318],
    ]

    connections.forEach((connection) => {
      ctx.beginPath()
      for (let i = 0; i < connection.length; i++) {
        const idx = connection[i]
        if (idx < landmarks.length) {
          const x = landmarks[idx].x * width
          const y = landmarks[idx].y * height

          if (i === 0) {
            ctx.moveTo(x, y)
          } else {
            ctx.lineTo(x, y)
          }
        }
      }
      ctx.closePath()
      ctx.stroke()
    })
  }

  // ë¬¸ì œ ë¶€ìœ„ ì‹œê°í™” (ì˜¤ë¥¸ìª½ ë³¼ ìœ„ì¹˜)
  const drawProblemArea = (
    ctx: CanvasRenderingContext2D,
    landmarks: NormalizedLandmark[],
    width: number,
    height: number
  ) => {
    // ì˜¤ë¥¸ìª½ ë³¼ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (ëŒ€ëµì ì¸ ìœ„ì¹˜)
    // MediaPipe FaceMeshì—ì„œ ë³¼ ì˜ì—­ì€ ëŒ€ëµ 234, 454, 227, 116, 117, 118, 119, 120, 121, 126, 142, 36, 205, 206, 207 ë“±
    // ì˜¤ë¥¸ìª½ ë³¼ ì¤‘ì‹¬ë¶€: ì¸ë±ìŠ¤ 234, 454 ì£¼ë³€
    const rightCheekIndices = [234, 227, 116, 117, 118, 119, 120, 121, 126, 142, 36, 205, 206, 207, 454]
    
    if (rightCheekIndices.length === 0) return

    // ì˜¤ë¥¸ìª½ ë³¼ ì¤‘ì‹¬ì  ê³„ì‚°
    let sumX = 0
    let sumY = 0
    let count = 0

    rightCheekIndices.forEach((idx) => {
      if (idx < landmarks.length) {
        sumX += landmarks[idx].x * width
        sumY += landmarks[idx].y * height
        count++
      }
    })

    if (count === 0) return

    const centerX = sumX / count
    const centerY = sumY / count

    // ë¹¨ê°„ìƒ‰ ë°˜íˆ¬ëª… ì› ê·¸ë¦¬ê¸° (ê¸°ë¯¸/ìƒ‰ì†Œ ì¹¨ì°© ì‹œê°í™”)
    const radius = 40
    ctx.fillStyle = 'rgba(255, 0, 0, 0.3)'
    ctx.strokeStyle = 'rgba(255, 0, 0, 0.6)'
    ctx.lineWidth = 2

    // ì™¸ê³½ ì›
    ctx.beginPath()
    ctx.arc(centerX, centerY, radius, 0, Math.PI * 2)
    ctx.fill()
    ctx.stroke()

    // ë‚´ë¶€ ì› (ë” ì§„í•œ ìƒ‰)
    ctx.beginPath()
    ctx.arc(centerX, centerY, radius * 0.6, 0, Math.PI * 2)
    ctx.fillStyle = 'rgba(255, 0, 0, 0.4)'
    ctx.fill()

    // íƒ€ê²Ÿ ì‹­ìì„ 
    ctx.strokeStyle = 'rgba(255, 0, 0, 0.8)'
    ctx.lineWidth = 1.5
    ctx.beginPath()
    ctx.moveTo(centerX - radius * 0.8, centerY)
    ctx.lineTo(centerX + radius * 0.8, centerY)
    ctx.moveTo(centerX, centerY - radius * 0.8)
    ctx.lineTo(centerX, centerY + radius * 0.8)
    ctx.stroke()
  }

  // ìŠ¤ìº” ë¼ì¸ ì• ë‹ˆë©”ì´ì…˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€, scanningStageì— ë”°ë¼ ë™ì‘)
  const drawScanLine = (ctx: CanvasRenderingContext2D, width: number, height: number) => {
    // processing ë‹¨ê³„ì¼ ë•ŒëŠ” ê¹œë¹¡ì´ëŠ” íš¨ê³¼ (í„ìŠ¤)
    if (scanningStage === 'processing') {
      const blink = Math.sin(Date.now() / 200) > 0
      if (!blink) return // ê¹œë¹¡ì„ íš¨ê³¼
    }

    // scanning ë‹¨ê³„ì¼ ë•Œë§Œ ë¼ì¸ ì´ë™ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if (scanningStage === 'scanning') {
      scanLineYRef.current += scanDirectionRef.current * 2 // ì†ë„ ì¡°ì ˆ

      // ê²½ê³„ ì²´í¬ ë° ë°©í–¥ ì „í™˜
      if (scanLineYRef.current >= height) {
        scanLineYRef.current = height
        scanDirectionRef.current = -1
      } else if (scanLineYRef.current <= 0) {
        scanLineYRef.current = 0
        scanDirectionRef.current = 1
      }
    }

    // ë¯¼íŠ¸ìƒ‰ ìŠ¤ìº” ë¼ì¸ ê·¸ë¦¬ê¸° (scanningStageì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½)
    const lineY = scanningStage === 'scanning' ? scanLineYRef.current : height / 2
    const gradient = ctx.createLinearGradient(0, lineY - 10, 0, lineY + 10)
    gradient.addColorStop(0, 'rgba(0, 255, 194, 0)') // ë¯¼íŠ¸ íˆ¬ëª…
    gradient.addColorStop(0.5, scanningStage === 'processing' ? 'rgba(0, 255, 194, 1)' : 'rgba(0, 255, 194, 0.8)') // processing ì¤‘ì¼ ë•Œ ë” ì§„í•˜ê²Œ
    gradient.addColorStop(1, 'rgba(0, 255, 194, 0)') // ë¯¼íŠ¸ íˆ¬ëª…

    ctx.strokeStyle = gradient
    ctx.lineWidth = scanningStage === 'processing' ? 4 : 3
    ctx.beginPath()
    ctx.moveTo(0, lineY)
    ctx.lineTo(width, lineY)
    ctx.stroke()

    // ìŠ¤ìº” ë¼ì¸ ìœ„ì•„ë˜ ê¸€ë¡œìš° íš¨ê³¼
    ctx.shadowBlur = scanningStage === 'processing' ? 20 : 15
    ctx.shadowColor = 'rgba(0, 255, 194, 0.6)'
    ctx.stroke()
    ctx.shadowBlur = 0
  }

  // ì¹´ë©”ë¼ í”„ë ˆì„ ì²˜ë¦¬
  const processFrame = useCallback(async () => {
    // ğŸ§¹ Cleanup ìƒíƒœ ì²´í¬: ì–¸ë§ˆìš´íŠ¸ëœ í›„ ì‹¤í–‰ ë°©ì§€
    if (isCleanedUpRef.current) {
      console.log('ğŸ§¹ [ARCamera] processFrame skipped - component cleaned up')
      return
    }

    const video = webcamRef.current?.video
    if (!faceMeshRef.current) {
      animationFrameRef.current = requestAnimationFrame(processFrame)
      return
    }

    try {
      if (isMockMode) {
        // Mock ëª¨ë“œ: ì´ë¯¸ì§€ ìš”ì†Œ ì‚¬ìš©
        const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
        if (mockImg && mockImg.complete && mockImg.naturalWidth > 0) {
          await faceMeshRef.current.send({ image: mockImg })
        }
      } else if (video && video.readyState === video.HAVE_ENOUGH_DATA) {
        // ğŸš€ ì´ì›í™” ì „ëµ: íŠ¸ë˜í‚¹ìš© ì¶•ì†Œ ìº”ë²„ìŠ¤ë¡œ MediaPipe ì—°ì‚° (ì„±ëŠ¥ ìµœì í™”)
        // ì›ë³¸ ë¹„ë””ì˜¤ ëŒ€ì‹  ì¶•ì†Œëœ ìº”ë²„ìŠ¤ë¥¼ MediaPipeì— ì „ë‹¬í•˜ì—¬ ì—°ì‚° ë¶€í•˜ ê°ì†Œ
        
        // íŠ¸ë˜í‚¹ìš© ìº”ë²„ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if (!trackingCanvasRef.current) {
          trackingCanvasRef.current = document.createElement('canvas')
        }
        
        const trackingCanvas = trackingCanvasRef.current
        const aspectRatio = video.videoHeight / video.videoWidth
        const trackingWidth = TRACKING_CANVAS_WIDTH
        const trackingHeight = Math.round(trackingWidth * aspectRatio)
        
        // ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì • (ë³€ê²½ ì‹œì—ë§Œ)
        if (trackingCanvas.width !== trackingWidth || trackingCanvas.height !== trackingHeight) {
          trackingCanvas.width = trackingWidth
          trackingCanvas.height = trackingHeight
        }
        
        // ì›ë³¸ ë¹„ë””ì˜¤ë¥¼ ì¶•ì†Œ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸° (ë¹ ë¥¸ ë‹¤ìš´ìƒ˜í”Œë§)
        const ctx = trackingCanvas.getContext('2d', { alpha: false })
        if (ctx) {
          ctx.drawImage(video, 0, 0, trackingWidth, trackingHeight)
          // ì¶•ì†Œëœ ì´ë¯¸ì§€ë¡œ MediaPipe ì—°ì‚° (ë°œì—´/ë ‰ ê°ì†Œ)
          await faceMeshRef.current.send({ image: trackingCanvas })
        }
      }
    } catch (error) {
      // ğŸ§¹ cleanup ì¤‘ ì—ëŸ¬ëŠ” ë¬´ì‹œ
      if (!isCleanedUpRef.current) {
        console.error('FaceMesh processing error:', error)
      }
    }

    // ğŸ§¹ cleanup ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ ë‹¤ìŒ í”„ë ˆì„ ì˜ˆì•½
    if (!isCleanedUpRef.current) {
      animationFrameRef.current = requestAnimationFrame(processFrame)
    }
  }, [isMockMode])

  // Webcam ì¤€ë¹„ ì™„ë£Œ ì‹œ í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘
  const handleUserMedia = useCallback(() => {
    setCameraError(null)
    setIsCameraReady(true)
    setIsCameraLoading(false)
    setScanningStage('idle') // ì´ˆê¸° ìƒíƒœë¥¼ idleë¡œ ì„¤ì •
    setBottomMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
    
    if (isModelReady) {
      setTimeout(() => {
        processFrame()
      }, 500)
    }
  }, [isModelReady, processFrame])

  // Mock Mode í™œì„±í™” ì‹œì—ë„ ì–¼êµ´ ê°ì§€ ìƒíƒœ ì„¤ì •
  useEffect(() => {
    if (isMockMode && !isCameraLoading) {
      setScanningStage('idle') // ì´ˆê¸° ìƒíƒœë¥¼ idleë¡œ ì„¤ì •
      setBottomMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
      // Mock ëª¨ë“œì—ì„œëŠ” í•­ìƒ ì–¼êµ´ì´ ê°ì§€ë˜ê³  ì •ë ¬ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
      setIsFaceDetected(true)
      setFaceAlignment('aligned')
      setGuideMessage('ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš” âœ¨')
      setGuideColor('mint')
      setFaceDetectionStartTime(Date.now())
      faceAlignmentStartTimeRef.current = Date.now() // Mock ëª¨ë“œì—ì„œ ì •ë ¬ ì‹œì‘ ì‹œê°„ ì„¤ì •
      faceDetectionDurationRef.current = 0
    } else if (!isMockMode) {
      // ì‹¤ì œ ì¹´ë©”ë¼ ëª¨ë“œë¡œ ì „í™˜ ì‹œ ì–¼êµ´ ê°ì§€ ìƒíƒœ ì´ˆê¸°í™”
      setIsFaceDetected(false)
      setFaceAlignment('none')
      setGuideMessage('ì–¼êµ´ì„ ê°€ì´ë“œ ì•ˆì— ë§ì¶°ì£¼ì„¸ìš”')
      setGuideColor('white')
      setFaceDetectionStartTime(null)
      faceAlignmentStartTimeRef.current = null
      faceDetectionDurationRef.current = 0
    }
  }, [isMockMode, isCameraLoading])

  // ì¹´ë©”ë¼ ì—ëŸ¬ ì²˜ë¦¬ - Mock Modeë¡œ ì „í™˜
  const handleUserMediaError = useCallback((error: string | DOMException) => {
    console.warn('Camera error - switching to Mock Mode:', error)
    setIsCameraLoading(false)
    setIsCameraReady(false)
    setIsMockMode(true)
    setCameraError(null) // ì—ëŸ¬ í™”ë©´ ëŒ€ì‹  Mock Mode ì‚¬ìš©
  }, [])

  // ì¹´ë©”ë¼ ì¬ì‹œë„
  const handleRetry = useCallback(() => {
    setCameraError(null)
    setIsCameraLoading(true)
    setIsCameraReady(false)
    setIsMockMode(false)
    
    // í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ì¹´ë©”ë¼ ì¬ìš”ì²­
    window.location.reload()
  }, [])

  // ğŸ¯ ì´ì›í™” ì „ëµ: ê³ í™”ì§ˆ ì´ë¯¸ì§€ ìº¡ì²˜ ë° ë„¤ë¹„ê²Œì´ì…˜ ì²˜ë¦¬ í•¨ìˆ˜
  const handleCaptureAndNavigate = useCallback(() => {
    try {
      const video = webcamRef.current?.video
      if (video || isMockMode) {
        const tempCanvas = document.createElement('canvas')
        if (isMockMode) {
          // Mock ëª¨ë“œì¼ ê²½ìš° Mock ì´ë¯¸ì§€ ì‚¬ìš©
            const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
            if (mockImg && mockImg.complete && mockImg.naturalWidth > 0) {
              try {
                tempCanvas.width = mockImg.naturalWidth
                tempCanvas.height = mockImg.naturalHeight
                const tempCtx = tempCanvas.getContext('2d')
                if (tempCtx) {
                  tempCtx.drawImage(mockImg, 0, 0)
                  // ğŸ¯ ìµœê³  í™”ì§ˆë¡œ ìº¡ì²˜ (ë¬´ì••ì¶•)
                  const imageData = tempCanvas.toDataURL('image/jpeg', CAPTURE_QUALITY)
                  sessionStorage.setItem('skinAnalysisImage', imageData)
                  console.log(`ğŸ“¸ [ARCamera] High-res capture: ${mockImg.naturalWidth}x${mockImg.naturalHeight}, Quality: ${CAPTURE_QUALITY}`)
                  
                  // MediaPipeë¡œ ë¶„ì„ëœ ì‹¤ì œ ëœë“œë§ˆí¬ ì‚¬ìš©
                  console.log('ğŸ’¾ [ARCamera] Saving landmarks:', {
                    hasLandmarks: !!landmarksRef.current,
                    landmarksLength: landmarksRef.current?.length || 0,
                  })
                  if (landmarksRef.current) {
                    sessionStorage.setItem('skinAnalysisLandmarks', JSON.stringify(landmarksRef.current))
                    console.log('âœ… [ARCamera] Landmarks saved to sessionStorage')
                  } else {
                    console.warn('âš ï¸ [ARCamera] No landmarks found in landmarksRef.current')
                  }
                }
              } catch (error) {
                console.error('Failed to save image/landmarks:', error)
                // CORS ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ëœë“œë§ˆí¬ë§Œ ì €ì¥í•˜ê³  ì§„í–‰
                if (landmarksRef.current) {
                  sessionStorage.setItem('skinAnalysisLandmarks', JSON.stringify(landmarksRef.current))
                }
              }
            // ì¹´ë©”ë¼ cleanup
            if (webcamRef.current?.video?.srcObject) {
              const stream = webcamRef.current.video.srcObject as MediaStream
              stream.getTracks().forEach(track => track.stop())
            }
            // ëª¨ë‹¬ ë‹«ê¸° & í˜ì´ì§€ ì´ë™
            onComplete?.()
            router.push('/report')
          } else {
            // ì´ë¯¸ì§€ê°€ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìƒˆë¡œ ë¡œë“œ
            const newMockImg = new Image()
            newMockImg.crossOrigin = 'anonymous'
            newMockImg.onload = () => {
              try {
                tempCanvas.width = newMockImg.width
                tempCanvas.height = newMockImg.height
                const tempCtx = tempCanvas.getContext('2d')
                if (tempCtx) {
                  tempCtx.drawImage(newMockImg, 0, 0)
                  // ğŸ¯ ìµœê³  í™”ì§ˆë¡œ ìº¡ì²˜ (ë¬´ì••ì¶•)
                  const imageData = tempCanvas.toDataURL('image/jpeg', CAPTURE_QUALITY)
                  sessionStorage.setItem('skinAnalysisImage', imageData)
                  
                  // MediaPipeë¡œ ë¶„ì„ëœ ì‹¤ì œ ëœë“œë§ˆí¬ ì‚¬ìš©
                  console.log('ğŸ’¾ [ARCamera] Saving landmarks:', {
                    hasLandmarks: !!landmarksRef.current,
                    landmarksLength: landmarksRef.current?.length || 0,
                  })
                  if (landmarksRef.current) {
                    sessionStorage.setItem('skinAnalysisLandmarks', JSON.stringify(landmarksRef.current))
                    console.log('âœ… [ARCamera] Landmarks saved to sessionStorage')
                  } else {
                    console.warn('âš ï¸ [ARCamera] No landmarks found in landmarksRef.current')
                  }
                }
                // ëª¨ë‹¬ ë‹«ê¸° & í˜ì´ì§€ ì´ë™
                onComplete?.()
                router.push('/report')
              } catch (error) {
                console.error('Failed to save image/landmarks:', error)
                onComplete?.()
                router.push('/report')
              }
            }
            newMockImg.onerror = () => {
              console.error('Failed to load mock image')
              onComplete?.()
              router.push('/report')
            }
            newMockImg.src = 'https://images.unsplash.com/photo-1500648767791-00dcc994a43e?q=80&w=1000&auto=format&fit=crop'
          }
        } else if (video) {
          // ğŸ¯ ì´ì›í™” ì „ëµ: ì‹¤ì œ ì¹´ë©”ë¼ - ì¹´ë©”ë¼ í•˜ë“œì›¨ì–´ ìµœëŒ€ í•´ìƒë„ë¡œ ìº¡ì²˜
          // video.videoWidth/HeightëŠ” ì¹´ë©”ë¼ì˜ ì‹¤ì œ í•´ìƒë„ (1920x1080 ë˜ëŠ” ê·¸ ì´ìƒ)
          const captureWidth = video.videoWidth
          const captureHeight = video.videoHeight
          
          tempCanvas.width = captureWidth
          tempCanvas.height = captureHeight
          const tempCtx = tempCanvas.getContext('2d', { alpha: false })
          if (tempCtx) {
            // ì›ë³¸ í•´ìƒë„ ê·¸ëŒ€ë¡œ ìº¡ì²˜ (resize ì—†ìŒ)
            tempCtx.drawImage(video, 0, 0, captureWidth, captureHeight)
            // ğŸ¯ ìµœê³  í™”ì§ˆë¡œ ì €ì¥ (ë¬´ì••ì¶•, ëª¨ê³µ ë””í…Œì¼ ìœ ì§€)
            const imageData = tempCanvas.toDataURL('image/jpeg', CAPTURE_QUALITY)
            sessionStorage.setItem('skinAnalysisImage', imageData)
            console.log(`ğŸ“¸ [ARCamera] High-res capture: ${captureWidth}x${captureHeight}, Quality: ${CAPTURE_QUALITY}`)
            
            if (landmarksRef.current) {
              sessionStorage.setItem('skinAnalysisLandmarks', JSON.stringify(landmarksRef.current))
            }
          }
          // ì¹´ë©”ë¼ cleanup
          if (webcamRef.current?.video?.srcObject) {
            const stream = webcamRef.current.video.srcObject as MediaStream
            stream.getTracks().forEach(track => track.stop())
          }
          // ëª¨ë‹¬ ë‹«ê¸° & í˜ì´ì§€ ì´ë™
          onComplete?.()
          router.push('/report')
        }
      }
    } catch (error) {
      console.error('Failed to save image/landmarks:', error)
      // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ í˜ì´ì§€ ì´ë™
      if (webcamRef.current?.video?.srcObject) {
        const stream = webcamRef.current.video.srcObject as MediaStream
        stream.getTracks().forEach(track => track.stop())
      }
      onComplete?.()
      router.push('/report')
    }
  }, [isMockMode, router, onComplete])

  // âš¡ í™”ë©´ ì •ì§€ í•¨ìˆ˜ (ê°€ë²¼ìš´ ì‘ì—…ë§Œ - ì¦‰ì‹œ UI ì—…ë°ì´íŠ¸)
  const freezeScreen = useCallback(() => {
    console.log('âš¡ [ARCamera] freezeScreen: Instant UI freeze started')
    
    // 1. MediaPipe ë£¨í”„ ì¦‰ì‹œ ì¤‘ë‹¨ (ë¦¬ì†ŒìŠ¤ í™•ë³´)
    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current)
      animationFrameRef.current = null
      console.log('âš¡ [ARCamera] MediaPipe loop stopped')
    }
    
    // 2. ì¦‰ì‹œ UI ìƒíƒœ ì—…ë°ì´íŠ¸ (ê°€ë²¼ìš´ ì‘ì—…)
    setIsShutterDisabled(true)
    setScanningStage('scanning')
    setBottomMessage('í”¼ë¶€ í‘œë©´ ìŠ¤ìº” ì¤‘... ì›€ì§ì´ì§€ ë§ˆì„¸ìš”')
    setLaserProgress(0)
    
    // 3. í˜„ì¬ ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë ¤ì„œ í™”ë©´ 'ì •ì§€' (Base64 ë³€í™˜ ì—†ìŒ!)
    const video = webcamRef.current?.video
    const canvas = canvasRef.current
    
    if (isMockMode) {
      // Mock ëª¨ë“œ: Mock ì´ë¯¸ì§€ë¡œ frozen frame ì„¤ì • (URLë§Œ ì„¤ì •, Base64 ë³€í™˜ X)
      const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
      if (mockImg && mockImg.complete) {
        // ìº”ë²„ìŠ¤ì— ì´ë¯¸ì§€ ê·¸ë¦¬ê¸° (UI ì •ì§€ìš©)
        if (canvas) {
          const ctx = canvas.getContext('2d')
          if (ctx) {
            canvas.width = mockImg.naturalWidth
            canvas.height = mockImg.naturalHeight
            ctx.drawImage(mockImg, 0, 0)
          }
        }
        // frozenFrameì— ì›ë³¸ URLë§Œ ì„¤ì • (ë¹ ë¦„)
        setFrozenFrame(mockImg.src)
      }
    } else if (video && canvas) {
      // ì‹¤ì œ ì¹´ë©”ë¼: ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
      const ctx = canvas.getContext('2d')
      if (ctx && video.videoWidth > 0 && video.videoHeight > 0) {
        canvas.width = video.videoWidth
        canvas.height = video.videoHeight
        ctx.drawImage(video, 0, 0)
        // frozenFrameì— ìº”ë²„ìŠ¤ ì°¸ì¡°ë§Œ ì„¤ì • (ì‹¤ì œ ë°ì´í„° ë³€í™˜ì€ ë‚˜ì¤‘ì—)
        // ì„ì‹œë¡œ ë¹ˆ ë¬¸ìì—´ ì„¤ì •í•˜ì—¬ frozen ìƒíƒœì„ì„ í‘œì‹œ
        setFrozenFrame('freezing')
      }
    }
    
    console.log('âš¡ [ARCamera] Screen frozen, animation starting...')
  }, [isMockMode])

  // ğŸ¬ ì‹œë„¤ë§ˆí‹± 3ë‹¨ê³„ ì‹œí€€ìŠ¤ ì‹¤í–‰ í•¨ìˆ˜ (ìµœì í™”ë¨)
  const executeCinematicSequence = useCallback(async () => {
    if (scanningStage !== 'idle') return // ì´ë¯¸ ì§„í–‰ ì¤‘ì´ë©´ ë¬´ì‹œ

    try {
      // ============================================
      // âš¡ Step 0: ì¦‰ì‹œ í™”ë©´ ì •ì§€ (ê°€ë²¼ìš´ ì‘ì—…ë§Œ!)
      // ============================================
      freezeScreen()
      
      // ============================================
      // ğŸ’¾ Step 1: ë°ì´í„° ì €ì¥ (500ms ë’¤ - Lazy Processing)
      // ============================================
      // ì‚¬ìš©ìëŠ” ì• ë‹ˆë©”ì´ì…˜ì„ ë³´ê³  ìˆìœ¼ë‹ˆ ë’·ë‹¨ì—ì„œ ì²˜ë¦¬
      setTimeout(() => {
        console.log('ğŸ’¾ [ARCamera] Lazy processing: Saving HIGH-RES image data...')
        
        let capturedImage: string | null = null
        
        if (isMockMode) {
          // Mock ëª¨ë“œ: Mock ì´ë¯¸ì§€ Base64 ë³€í™˜
          const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
          if (mockImg && mockImg.complete) {
            const tempCanvas = document.createElement('canvas')
            tempCanvas.width = mockImg.naturalWidth
            tempCanvas.height = mockImg.naturalHeight
            const ctx = tempCanvas.getContext('2d')
            if (ctx) {
              ctx.drawImage(mockImg, 0, 0)
              // ğŸ¯ ìµœê³  í™”ì§ˆë¡œ ìº¡ì²˜ (ë¬´ì••ì¶•)
              capturedImage = tempCanvas.toDataURL('image/jpeg', CAPTURE_QUALITY)
              console.log(`ğŸ“¸ [ARCamera] High-res capture: ${mockImg.naturalWidth}x${mockImg.naturalHeight}`)
            }
          }
        } else {
          // ğŸ¯ ì´ì›í™” ì „ëµ: ì‹¤ì œ ì¹´ë©”ë¼ - ìº”ë²„ìŠ¤ì— ì €ì¥ëœ ì›ë³¸ í•´ìƒë„ ì´ë¯¸ì§€ ì‚¬ìš©
          const canvas = canvasRef.current
          if (canvas && canvas.width > 0 && canvas.height > 0) {
            // ìº”ë²„ìŠ¤ì—ëŠ” video.videoWidth x video.videoHeight (ì¹´ë©”ë¼ ìµœëŒ€ í•´ìƒë„)ê°€ ì €ì¥ë¨
            capturedImage = canvas.toDataURL('image/jpeg', CAPTURE_QUALITY)
            console.log(`ğŸ“¸ [ARCamera] High-res capture: ${canvas.width}x${canvas.height}, Quality: ${CAPTURE_QUALITY}`)
          }
        }
        
        // ì„¸ì…˜ ìŠ¤í† ë¦¬ì§€ì— ì €ì¥
        if (capturedImage) {
          sessionStorage.setItem('skinAnalysisImage', capturedImage)
          setFrozenFrame(capturedImage) // ì‹¤ì œ ì´ë¯¸ì§€ë¡œ ì—…ë°ì´íŠ¸
          console.log('ğŸ’¾ [ARCamera] High-quality image data saved to sessionStorage')
        }
        
        // ëœë“œë§ˆí¬ë„ ì €ì¥
        if (landmarksRef.current) {
          sessionStorage.setItem('skinAnalysisLandmarks', JSON.stringify(landmarksRef.current))
        }
      }, 500) // 500ms ì§€ì—°

      // ============================================
      // ğŸ”¦ Step 2: ë ˆì´ì € ìŠ¤ìºë‹ (Laser Beam) - ì¦‰ì‹œ ì‹œì‘
      // ============================================

      // ë ˆì´ì € ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (Mesh Reveal íš¨ê³¼ìš©) - 3.5ì´ˆ
      const progressInterval = setInterval(() => {
        setLaserProgress(prev => {
          if (prev >= 100) {
            clearInterval(progressInterval)
            return 100
          }
          return prev + (100 / 35) // 3.5ì´ˆ ë™ì•ˆ 100%
        })
      }, 100)

      // ë ˆì´ì € ë°” ì• ë‹ˆë©”ì´ì…˜: ìƒë‹¨(-10%)ì—ì„œ í•˜ë‹¨(110%)ê¹Œì§€ (3.5ì´ˆ - ëŠë¦¬ê²Œ)
      await laserControls.start({
        y: ['-10%', '110%'],
        transition: {
          duration: 3.5,
          ease: 'linear', // ì¼ì •í•œ ì†ë„ë¡œ ì´ë™
        },
      })

      clearInterval(progressInterval)
      setLaserProgress(100)

      // ============================================
      // ğŸ“¡ Step 3: ë°ì´í„° ì „ì†¡ ì—°ì¶œ (Data Transfer)
      // ============================================
      setScanningStage('processing')
      setShowDataTransfer(true)
      setBottomMessage('ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ. ë¶„ì„ ì„œë²„ë¡œ ì „ì†¡ ì¤‘...')

      // ì›í˜• íŒŒë™ ì• ë‹ˆë©”ì´ì…˜ (1.5ì´ˆ)
      await rippleControls.start({
        scale: [0, 3],
        opacity: [0.8, 0],
        transition: {
          duration: 1.5,
          ease: 'easeOut',
        },
      })

      // ============================================
      // ğŸ¬ Step 4: íŠ¸ëœì§€ì…˜ (Transition)
      // ============================================
      setScanningStage('complete')
      setBottomMessage('ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ')

      // í˜ì´ë“œ ì•„ì›ƒ ì• ë‹ˆë©”ì´ì…˜
      await fadeControls.start({
        opacity: 1,
        transition: {
          duration: 0.5,
          ease: 'easeInOut',
        },
      })

      // ì´ë¯¸ì§€ ìº¡ì²˜ ë° ë„¤ë¹„ê²Œì´ì…˜
      handleCaptureAndNavigate()
    } catch (error) {
      console.error('Cinematic sequence error:', error)
      // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ í˜ì´ì§€ ì´ë™
      handleCaptureAndNavigate()
    }
  }, [scanningStage, isMockMode, laserControls, faceMeshControls, fadeControls, rippleControls, handleCaptureAndNavigate, freezeScreen])

  // executeCinematicSequenceë¥¼ refì— ì €ì¥ (ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°)
  useEffect(() => {
    executeCinematicSequenceRef.current = executeCinematicSequence
  }, [executeCinematicSequence])

  // ğŸ¯ í•¸ì¦ˆí”„ë¦¬ ì˜¤í†  ìº¡ì²˜ ë¡œì§ (Hands-free Auto Capture) - ì¸í„°ë²Œ ê¸°ë°˜
  useEffect(() => {
    // ìŠ¤ìº” ì¤‘ì´ë©´ ë¬´ì‹œ
    if (scanningStage !== 'idle') {
      return
    }

    const LOCK_ON_DURATION = 2000 // 2ì´ˆ
    
    // 3ë‹¨ê³„ ê²€ì¦ì´ ëª¨ë‘ Passì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜
    const checkConditions = () => {
      return (
        (faceAlignment === 'aligned' || isMockMode) &&
        lightingStatus === 'ok' &&
        poseStatus === 'ok'
      )
    }

    // ì¡°ê±´ ì²´í¬ ë° ì˜¤í†  ìº¡ì²˜ ì‹¤í–‰ ì¸í„°ë²Œ
    const intervalId = setInterval(() => {
      // ì´ë¯¸ ìº¡ì²˜ê°€ íŠ¸ë¦¬ê±°ëìœ¼ë©´ ì¤‘ë‹¨
      if (autoCaptureTriggeredRef.current) {
        clearInterval(intervalId)
        return
      }

      const isAllConditionsMet = checkConditions()

      if (isAllConditionsMet) {
        // ë½ì˜¨ ì‹œì‘
        if (lockOnStartTimeRef.current === null) {
          lockOnStartTimeRef.current = Date.now()
          console.log('ğŸ¯ Lock-on started')
        }

        const elapsed = Date.now() - lockOnStartTimeRef.current
        const progress = Math.min((elapsed / LOCK_ON_DURATION) * 100, 100)
        setLockOnProgress(progress)

        // ì¹´ìš´íŠ¸ë‹¤ìš´ í…ìŠ¤íŠ¸ (2..1)
        const remaining = Math.ceil((LOCK_ON_DURATION - elapsed) / 1000)
        if (remaining > 0 && remaining <= 2) {
          setCountdownText(`${remaining}`)
          setBottomMessage(`âœ¨ ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš” (${remaining}...)`)
        } else if (remaining <= 0) {
          setCountdownText(null)
          setBottomMessage('ğŸ“¸ ì´¬ì˜!')
        } else {
          setCountdownText(null)
          setBottomMessage('âœ¨ ì™„ë²½í•´ìš”! ì›€ì§ì´ì§€ ë§ˆì„¸ìš”')
        }

        // 2ì´ˆ ê²½ê³¼ -> ì˜¤í†  ìº¡ì²˜ ì‹¤í–‰
        if (elapsed >= LOCK_ON_DURATION && !autoCaptureTriggeredRef.current) {
          autoCaptureTriggeredRef.current = true
          setLockOnProgress(100)
          clearInterval(intervalId)
          
          console.log('ğŸ“¸ Auto capture triggered!')
          // ì‹œë„¤ë§ˆí‹± ì‹œí€€ìŠ¤ ì‹¤í–‰ (refë¥¼ í†µí•´ í˜¸ì¶œ)
          if (executeCinematicSequenceRef.current) {
            executeCinematicSequenceRef.current()
          }
        }
      } else {
        // ì¡°ê±´ ì‹¤íŒ¨ -> íƒ€ì´ë¨¸ ë¦¬ì…‹
        if (lockOnStartTimeRef.current !== null) {
          console.log('âŒ Lock-on reset - conditions not met')
          lockOnStartTimeRef.current = null
          setLockOnProgress(0)
          setCountdownText(null)
        }
      }
    }, 100) // 100msë§ˆë‹¤ ì²´í¬

    return () => {
      clearInterval(intervalId)
    }
  }, [scanningStage, isMockMode, faceAlignment, lightingStatus, poseStatus])

  // ìŠ¤ìº” ì™„ë£Œ í›„ ì˜¤í† ìº¡ì²˜ í”Œë˜ê·¸ ë¦¬ì…‹
  useEffect(() => {
    if (scanningStage === 'idle') {
      autoCaptureTriggeredRef.current = false
      lockOnStartTimeRef.current = null
      setLockOnProgress(0)
      setCountdownText(null)
    }
  }, [scanningStage])

  // ìŠ¤ìº” ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ë¡œì§ ì œê±° - ë ˆì´ì € ë°” ì• ë‹ˆë©”ì´ì…˜ìœ¼ë¡œ ëŒ€ì²´)
  // ì£¼ì„: scanningStageë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ scanStatusëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

  // Canvas ì• ë‹ˆë©”ì´ì…˜ (ìŠ¤ìº” ë¼ì¸ ê·¸ë¦¬ê¸°)
  useEffect(() => {
    if ((isCameraReady || isMockMode) && canvasRef.current) {
      const canvas = canvasRef.current
      const ctx = canvas.getContext('2d')
      if (!ctx) return

      let isAnimating = true

      const animate = () => {
        if (!isAnimating || scanningStage === 'complete') return
        
        // Canvas í¬ê¸° ì„¤ì •
        const container = canvas.parentElement
        if (container) {
          canvas.width = container.clientWidth || 640
          canvas.height = container.clientHeight || 480
        } else {
          canvas.width = 640
          canvas.height = 480
        }

        ctx.clearRect(0, 0, canvas.width, canvas.height)
        drawScanLine(ctx, canvas.width, canvas.height)
        
        if (isAnimating) {
          requestAnimationFrame(animate)
        }
      }
      
      const frameId = requestAnimationFrame(animate)
      
      return () => {
        isAnimating = false
        cancelAnimationFrame(frameId)
      }
    }
  }, [isCameraReady, isMockMode, scanningStage])

  // ëª¨ë¸ì´ ì¤€ë¹„ë˜ë©´ í”„ë ˆì„ ì²˜ë¦¬ ì‹œì‘
  useEffect(() => {
    if (isModelReady) {
      if (isMockMode) {
        // Mock ëª¨ë“œ: ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ë©´ ì²˜ë¦¬ ì‹œì‘
        const mockImg = document.querySelector('img[alt="Mock face for development"]') as HTMLImageElement
        if (mockImg) {
          if (mockImg.complete) {
            processFrame()
          } else {
            mockImg.onload = () => {
              processFrame()
            }
          }
        }
      } else if (webcamRef.current?.video) {
        const video = webcamRef.current.video
        if (video.readyState >= video.HAVE_METADATA) {
          processFrame()
        }
      }
    }
  }, [isModelReady, isMockMode, processFrame])

  // ğŸš€ Lazy Initialization: isReadyê°€ falseë©´ ê°€ë²¼ìš´ ë¡œë”© UIë§Œ í‘œì‹œ
  if (!isReady) {
    return (
      <div className={`relative w-full h-full ${className} bg-gray-900 flex items-center justify-center`}>
        <div className="text-center">
          {/* ğŸš€ GPU ìµœì í™” ë¡œë”© ìŠ¤í”¼ë„ˆ */}
          <div className="relative w-20 h-20 mx-auto mb-6 gpu-accelerated">
            <div className="absolute inset-0 rounded-full border-4 border-gray-800" />
            <div className="absolute inset-0 rounded-full border-4 border-[#00FFC2] border-t-transparent animate-gpu-spin" />
            <div className="absolute inset-2 rounded-full border-2 border-[#00FFC2]/30 border-t-transparent animate-gpu-spin-reverse" />
          </div>
          
          {/* í…ìŠ¤íŠ¸ */}
          <p className="text-white text-lg font-medium mb-2">ì¹´ë©”ë¼ ì¤€ë¹„ ì¤‘...</p>
          <p className="text-gray-400 text-sm">ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”</p>
          
          {/* ğŸš€ GPU ìµœì í™” ë¡œë”© ë°” */}
          <div className="mt-6 w-48 h-1 bg-gray-800 rounded-full overflow-hidden mx-auto">
            <div className="h-full w-1/2 bg-gradient-to-r from-[#00FFC2] to-[#00E6B8] rounded-full animate-loading-slide" />
          </div>
        </div>
        
        {/* ë°°ê²½ ê·¸ë¼ë°ì´ì…˜ íš¨ê³¼ */}
        <div className="absolute inset-0 bg-gradient-to-b from-transparent via-transparent to-[#00FFC2]/5 pointer-events-none" />
      </div>
    )
  }

  return (
    <div className={`relative w-full h-full ${className}`}>
      {/* Dev Mode ë±ƒì§€ */}
      {isMockMode && (
        <div className="absolute top-4 left-1/2 -translate-x-1/2 z-20 px-3 py-1.5 bg-yellow-500/90 backdrop-blur-sm rounded-full flex items-center gap-2">
          <span className="text-xs">âš ï¸</span>
          <span className="text-xs font-semibold text-black">Dev Mode: Camera Mockup</span>
        </div>
      )}

      {/* Webcam ë˜ëŠ” Mock ì´ë¯¸ì§€ */}
      {isMockMode ? (
        <img
          src="https://images.unsplash.com/photo-1500648767791-00dcc994a43e?q=80&w=1000&auto=format&fit=crop"
          alt="Mock face for development"
          crossOrigin="anonymous"
          className="absolute inset-0 w-full h-full object-contain bg-gray-900 scale-90"
          style={{
            objectPosition: 'center 40%', // ì–¼êµ´ì´ ê°€ì´ë“œë¼ì¸ ìœ„ì¹˜ì— ë§ë„ë¡ ì¡°ì •
          }}
        />
      ) : (
        <Webcam
          ref={webcamRef}
          audio={false}
          videoConstraints={{
            // ğŸ¯ ì´ì›í™” ì „ëµ: ì¹´ë©”ë¼ëŠ” ìµœëŒ€ í•´ìƒë„ë¡œ ìœ ì§€ (ê³ í™”ì§ˆ ìº¡ì²˜ìš©)
            // íŠ¸ë˜í‚¹ì€ ì¶•ì†Œ ìº”ë²„ìŠ¤ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì›ë³¸ í•´ìƒë„ ìœ ì§€í•´ë„ ì„±ëŠ¥ OK
            width: { ideal: CAPTURE_WIDTH, min: 1280 },
            height: { ideal: CAPTURE_HEIGHT, min: 720 },
            facingMode: 'user',
            frameRate: { ideal: 30, max: 30 },
          }}
          onUserMedia={handleUserMedia}
          onUserMediaError={handleUserMediaError}
          className="absolute inset-0 w-full h-full object-cover bg-gray-900"
          mirrored
        />
      )}

      {/* Canvas (AR ì˜¤ë²„ë ˆì´) */}
      <canvas
        ref={canvasRef}
        className="absolute inset-0 w-full h-full pointer-events-none z-10"
      />

      {/* ìŠ¤ìºë„ˆ ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´ (Dark Overlay with Elliptical Cutout) */}
      {(isCameraReady || isMockMode) && scanningStage !== 'complete' && (
        <>
          {/* SVG ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•œ ì˜¤ë²„ë ˆì´ (íƒ€ì›í˜• êµ¬ë© ëš«ê¸°) - í™”ë©´ ì¡°ëª… ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½ */}
          <svg className="absolute inset-0 w-full h-full pointer-events-none z-15" style={{ height: '100%' }}>
            <defs>
              <mask id="scanner-mask">
                {/* ì „ì²´ í™”ë©´ì„ í°ìƒ‰ìœ¼ë¡œ (ë§ˆìŠ¤í¬ì—ì„œ í°ìƒ‰ = ë¶ˆíˆ¬ëª…, ì˜¤ë²„ë ˆì´ê°€ ë³´ì„) */}
                <rect width="100%" height="100%" fill="white" />
                {/* íƒ€ì›í˜• ì˜ì—­ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ (ë§ˆìŠ¤í¬ì—ì„œ ê²€ì€ìƒ‰ = íˆ¬ëª…, ì›ë³¸ì´ ë³´ì„) */}
                <ellipse cx="50%" cy="40%" rx="35%" ry="27.5%" fill="black" />
              </mask>
            </defs>
            {/* ì˜¤ë²„ë ˆì´ (ë§ˆìŠ¤í¬ ì ìš©) - í™”ë©´ ì¡°ëª… ìƒíƒœì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½ */}
            <rect 
              width="100%" 
              height="100%" 
              fill={isScreenLightOn ? 'rgba(255, 255, 255, 0.9)' : 'rgba(0, 0, 0, 0.6)'} 
              mask="url(#scanner-mask)"
              className="transition-colors duration-300"
            />
          </svg>
          
          {/* ê°€ì´ë“œë¼ì¸ ì»¨í…Œì´ë„ˆ */}
          <div className="absolute inset-0 flex items-start justify-center pointer-events-none z-16 pt-[15%]">
            {/* ì„¸ë¡œë¡œ ê¸´ íƒ€ì›í˜• ê°€ì´ë“œë¼ì¸ (í™”ë©´ ë„ˆë¹„ì˜ 70%, ë†’ì´ì˜ 55%) */}
            <div className="relative w-[70%] aspect-[3/4]">
              {/* SVG íƒ€ì›í˜• ê°€ì´ë“œë¼ì¸ + ì§„í–‰ë¥  ê²Œì´ì§€ */}
              <svg 
                className="absolute inset-0 w-full h-full"
                viewBox="0 0 200 267"
                preserveAspectRatio="none"
              >
                {/* ë°°ê²½ íƒ€ì› (ì ì„  ë˜ëŠ” ì‹¤ì„ ) */}
                <ellipse
                  cx="100"
                  cy="133.5"
                  rx="95"
                  ry="128"
                  fill="none"
                  stroke={
                    lockOnProgress > 0 
                      ? 'rgba(255, 255, 255, 0.2)' 
                      : guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode)
                      ? '#00FFC2'
                      : guideColor === 'yellow'
                      ? '#FBBF24'
                      : 'rgba(255, 255, 255, 0.5)'
                  }
                  strokeWidth={lockOnProgress > 0 ? '2' : '3'}
                  strokeDasharray={
                    guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode) || lockOnProgress > 0
                      ? 'none'
                      : '8 4'
                  }
                  style={{
                    filter: guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode)
                      ? 'drop-shadow(0 0 10px rgba(0, 255, 194, 0.5))'
                      : guideColor === 'yellow'
                      ? 'drop-shadow(0 0 10px rgba(251, 191, 36, 0.5))'
                      : 'none',
                    transition: 'all 0.3s ease',
                  }}
                />
                
                {/* ğŸ¯ ì§„í–‰ë¥  ê²Œì´ì§€ (Lock-on Progress) */}
                {lockOnProgress > 0 && (
                  <ellipse
                    cx="100"
                    cy="133.5"
                    rx="95"
                    ry="128"
                    fill="none"
                    stroke="#00FFC2"
                    strokeWidth="4"
                    strokeLinecap="round"
                    style={{
                      // íƒ€ì› ë‘˜ë ˆ ê³„ì‚°: ì•½ 2 * Ï€ * sqrt((aÂ² + bÂ²) / 2) â‰ˆ 702
                      strokeDasharray: '702',
                      strokeDashoffset: `${702 - (702 * lockOnProgress) / 100}`,
                      filter: 'drop-shadow(0 0 15px rgba(0, 255, 194, 0.8)) drop-shadow(0 0 30px rgba(0, 255, 194, 0.4))',
                      transition: 'stroke-dashoffset 0.05s linear',
                      transformOrigin: 'center',
                      transform: 'rotate(-90deg) scaleX(-1)',
                    }}
                  />
                )}
              </svg>
              
              {/* ì¹´ìš´íŠ¸ë‹¤ìš´ ìˆ«ì í‘œì‹œ (ì¤‘ì•™) */}
              <AnimatePresence>
                {countdownText && (
                  <motion.div
                    key={countdownText}
                    initial={{ scale: 2, opacity: 0 }}
                    animate={{ scale: 1, opacity: 1 }}
                    exit={{ scale: 0.5, opacity: 0 }}
                    transition={{ duration: 0.3, ease: 'easeOut' }}
                    className="absolute inset-0 flex items-center justify-center"
                  >
                    <span 
                      className="text-8xl font-black text-[#00FFC2]"
                      style={{
                        textShadow: '0 0 30px rgba(0, 255, 194, 0.8), 0 0 60px rgba(0, 255, 194, 0.4)',
                      }}
                    >
                      {countdownText}
                    </span>
                  </motion.div>
                )}
              </AnimatePresence>
              
              {/* ë‚´ë¶€ ê°€ì´ë“œ (ë” ì‘ì€ íƒ€ì›) */}
              <div 
                className={`absolute inset-[8%] rounded-[50%] border transition-all duration-300 ${
                  guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode)
                    ? 'border-[1.5px] border-[#00FFC2]' 
                    : guideColor === 'yellow'
                    ? 'border-[1.5px] border-yellow-400'
                    : 'border border-dashed border-white'
                }`}
                style={{
                  opacity: guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode) ? 0.6 : 0.4,
                }}
              />
              
              {/* ê°€ì´ë“œë¼ì¸ ë°”ê¹¥ìª½ í•˜ë‹¨ í…ìŠ¤íŠ¸ */}
              <div className="absolute -bottom-12 left-1/2 -translate-x-1/2 text-center w-full">
                <p 
                  className={`text-lg font-bold transition-colors duration-300 ${
                    guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode)
                      ? 'text-[#00FFC2]' 
                      : guideColor === 'yellow'
                      ? 'text-yellow-400'
                      : 'text-white'
                  }`}
                  style={{
                    textShadow: guideColor === 'mint' || (faceAlignment === 'aligned' || isMockMode)
                      ? '0 0 8px rgba(0, 255, 194, 0.8)'
                      : guideColor === 'yellow'
                      ? '0 0 8px rgba(251, 191, 36, 0.8)'
                      : '0 0 4px rgba(255, 255, 255, 0.5)',
                  }}
                >
                  {guideMessage}
                </p>
              </div>
            </div>
          </div>
        </>
      )}

      {/* ğŸ“¸ ì •ì§€ í”„ë ˆì„ ì˜¤ë²„ë ˆì´ (Freeze Frame) - ìµœì í™”ë¨ */}
      <AnimatePresence>
        {frozenFrame && scanningStage !== 'idle' && (
          <motion.div
            key="frozen-frame"
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            transition={{ duration: 0.1 }}
            className="absolute inset-0 z-15"
          >
            {/* 'freezing' ìƒíƒœ: ìº”ë²„ìŠ¤ê°€ ì´ë¯¸ í™”ë©´ì— ê·¸ë ¤ì ¸ ìˆìœ¼ë¯€ë¡œ 
                ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´ë§Œ í‘œì‹œ (ì‹¤ì œ ìº”ë²„ìŠ¤ëŠ” ë°°ê²½ì— ìˆìŒ) */}
            {frozenFrame === 'freezing' ? (
              <div 
                className="w-full h-full bg-transparent"
                style={{ 
                  // ìº”ë²„ìŠ¤ ìœ„ì— ì˜¤ë²„ë ˆì´ë˜ë¯€ë¡œ íˆ¬ëª…í•˜ê²Œ
                }}
              />
            ) : (
              // ì‹¤ì œ Base64 ì´ë¯¸ì§€ê°€ ìˆì„ ë•Œ
              <img
                src={frozenFrame}
                alt="Captured frame"
                className="w-full h-full object-cover"
                style={{ 
                  objectPosition: 'center 40%',
                  transform: isMockMode ? 'scale(0.9)' : 'scaleX(-1)', // ì‹¤ì œ ì¹´ë©”ë¼ëŠ” ë¯¸ëŸ¬ë§
                }}
              />
            )}
          </motion.div>
        )}
      </AnimatePresence>

      {/* ğŸ”¦ í•˜ì´ì—”ë“œ ë ˆì´ì € ìŠ¤ìº” ë°” (Laser Beam) - ë” ë‘ê»ê³  ëˆˆì— ë„ê²Œ */}
      <AnimatePresence>
        {scanningStage === 'scanning' && (
          <motion.div
            key="laser-beam"
            initial={{ y: '-10%' }}
            animate={laserControls}
            exit={{ opacity: 0, transition: { duration: 0.5 } }}
            className="absolute left-0 right-0 z-35 pointer-events-none"
            style={{ top: 0 }}
          >
            {/* ê¸€ë¡œìš° ë°°ê²½ (ë” ë„“ì€ ë²”ìœ„) */}
            <div 
              className="absolute -top-8 left-0 right-0 h-32"
              style={{
                background: 'linear-gradient(to bottom, transparent 0%, rgba(0, 255, 194, 0.15) 30%, rgba(0, 255, 194, 0.3) 50%, rgba(0, 255, 194, 0.15) 70%, transparent 100%)',
              }}
            />
            
            {/* ğŸš€ GPU ìµœì í™”: ë©”ì¸ ë ˆì´ì € ë°” (ì •ì  boxShadow + opacity ì• ë‹ˆë©”ì´ì…˜) */}
            <div className="relative w-full h-24 gpu-accelerated">
              {/* ê¸€ë¡œìš° ë ˆì´ì–´ (ì •ì , opacityë§Œ ë³€ê²½) */}
              <div 
                className="absolute inset-0 bg-gradient-to-b from-transparent via-[#00FFC2] to-transparent neon-glow-mint-intense animate-glow-pulse"
              />
              {/* ë©”ì¸ ì»¬ëŸ¬ ë°” */}
              <div className="absolute inset-0 bg-gradient-to-b from-transparent via-[#00FFC2]/80 to-transparent" />
            </div>
            
            {/* ğŸš€ GPU ìµœì í™”: ë ˆì´ì € ì¤‘ì‹¬ì„  (ì •ì  ê¸€ë¡œìš°) */}
            <div className="absolute top-1/2 left-0 right-0 -translate-y-1/2 gpu-accelerated">
              {/* ê¸€ë¡œìš° ë ˆì´ì–´ */}
              <div className="h-3 bg-white/50 neon-glow-mint animate-glow-pulse" />
              {/* ë©”ì¸ ë¼ì¸ */}
              <div className="absolute inset-0 h-2 top-0.5 bg-white" />
            </div>
            
            {/* ì¢Œìš° í…Œì´í¼ íš¨ê³¼ */}
            <div className="absolute inset-0 bg-gradient-to-r from-black/30 via-transparent to-black/30" />
            
            {/* ğŸš€ GPU ìµœì í™”: ìŠ¤ìº” ë¼ì¸ í•˜ë‹¨ í•˜ì´ë¼ì´íŠ¸ (ì •ì  ê¸€ë¡œìš°) */}
            <div className="absolute -bottom-2 left-0 right-0 h-1 bg-[#00FFC2] neon-glow-mint" />
          </motion.div>
        )}
      </AnimatePresence>

      {/* ğŸŒ AR Face Mesh Reveal íš¨ê³¼ (ë ˆì´ì €ê°€ ì§€ë‚˜ê°„ ìë¦¬ì— ë“œëŸ¬ë‚¨) */}
      <AnimatePresence>
        {(scanningStage === 'scanning' || scanningStage === 'processing') && laserProgress > 0 && (
          <motion.div
            key="mesh-reveal"
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="absolute inset-0 z-20 pointer-events-none overflow-hidden"
          >
            {/* ìŠ¤ìº”ëœ ì˜ì—­ì— ë©”ì‰¬ ê·¸ë¦¬ë“œ í‘œì‹œ */}
            <div 
              className="absolute inset-0"
              style={{
                clipPath: `polygon(0 0, 100% 0, 100% ${laserProgress}%, 0 ${laserProgress}%)`,
              }}
            >
              {/* ë¯¼íŠ¸ìƒ‰ ê·¸ë¦¬ë“œ íŒ¨í„´ */}
              <div 
                className="w-full h-full opacity-30"
                style={{
                  backgroundImage: `
                    linear-gradient(rgba(0, 255, 194, 0.3) 1px, transparent 1px),
                    linear-gradient(90deg, rgba(0, 255, 194, 0.3) 1px, transparent 1px)
                  `,
                  backgroundSize: '20px 20px',
                }}
              />
              {/* ğŸš€ GPU ìµœì í™”: ë°ì´í„° í¬ì¸íŠ¸ ì‹œê°í™” (ì •ì  ê·¸ë¦¼ì) */}
              <div className="absolute inset-0 flex items-center justify-center gpu-accelerated">
                <div className="w-48 h-48 rounded-full border border-[#00FFC2]/50 bg-[#00FFC2]/5" />
              </div>
            </div>
          </motion.div>
        )}
      </AnimatePresence>

      {/* ğŸ“¡ ë°ì´í„° ì „ì†¡ ì—°ì¶œ (ì›í˜• íŒŒë™ + ì  ë°˜ì§ì„) */}
      <AnimatePresence>
        {showDataTransfer && (
          <motion.div
            key="data-transfer"
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="absolute inset-0 z-25 pointer-events-none flex items-center justify-center"
          >
            {/* ì¤‘ì•™ ë°ì´í„° í¬ì¸íŠ¸ */}
            <div className="relative">
              {/* ì›í˜• íŒŒë™ 1 */}
              <motion.div
                animate={rippleControls}
                className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-20 h-20 rounded-full border-2 border-[#00FFC2]"
              />
              {/* ì›í˜• íŒŒë™ 2 (ë”œë ˆì´) */}
              <motion.div
                initial={{ scale: 0, opacity: 0.8 }}
                animate={{ scale: 3, opacity: 0 }}
                transition={{ duration: 1.5, delay: 0.3, ease: 'easeOut' }}
                className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-20 h-20 rounded-full border-2 border-[#00FFC2]"
              />
              {/* ì›í˜• íŒŒë™ 3 (ë”œë ˆì´) */}
              <motion.div
                initial={{ scale: 0, opacity: 0.8 }}
                animate={{ scale: 3, opacity: 0 }}
                transition={{ duration: 1.5, delay: 0.6, ease: 'easeOut' }}
                className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-20 h-20 rounded-full border-2 border-[#00FFC2]"
              />
              {/* ğŸš€ GPU ìµœì í™”: ì¤‘ì•™ ê¸€ë¡œìš° (ì •ì  ê¸€ë¡œìš° + opacity í„ìŠ¤) */}
              <div className="w-8 h-8 rounded-full bg-[#00FFC2] neon-glow-mint animate-gpu-pulse gpu-accelerated" />
            </div>

            {/* ğŸš€ GPU ìµœì í™”: ë°˜ì§ì´ëŠ” ë°ì´í„° ì ë“¤ (CSS blinkë¡œ ëŒ€ì²´) */}
            {[...Array(8)].map((_, i) => (
              <div
                key={i}
                className={`absolute w-2 h-2 rounded-full bg-[#00FFC2] neon-glow-mint gpu-accelerated ${
                  i % 3 === 0 ? 'animate-blink' : i % 3 === 1 ? 'animate-blink-delay-1' : 'animate-blink-delay-2'
                }`}
                style={{
                  top: `${35 + (i % 4) * 10}%`,
                  left: `${25 + (i % 5) * 12}%`,
                }}
              />
            ))}
          </motion.div>
        )}
      </AnimatePresence>

      {/* í˜ì´ë“œ ì•„ì›ƒ ì˜¤ë²„ë ˆì´ (Stage 3) */}
      <AnimatePresence>
        {scanningStage === 'complete' && (
          <motion.div
            key="fade-out"
            initial={{ opacity: 0 }}
            animate={fadeControls}
            exit={{ opacity: 1 }}
            className="absolute inset-0 bg-black z-50 pointer-events-none"
          />
        )}
      </AnimatePresence>

      {/* í•˜ë‹¨ ìƒíƒœ ë©”ì‹œì§€ ë° ì…”í„° ë²„íŠ¼ */}
      {(isCameraReady || isMockMode) && scanningStage !== 'complete' && (
        <div className="absolute bottom-8 left-1/2 -translate-x-1/2 z-40 text-center px-6 w-full max-w-md">
          {/* ğŸš€ GPU ìµœì í™”: ìƒíƒœ ë©”ì‹œì§€ (ì •ì  ê¸€ë¡œìš°) */}
          <div 
            className={`bg-black/80 backdrop-blur-md rounded-2xl px-6 py-4 inline-block mb-4 border border-[#00FFC2]/20 gpu-accelerated ${
              scanningStage !== 'idle' ? 'neon-glow-mint animate-glow-pulse' : ''
            }`}
          >
            <p className="text-white text-sm font-medium">
              {bottomMessage}
            </p>
            {scanningStage === 'scanning' && (
              <div className="mt-3">
                <div className="flex items-center justify-between text-xs text-[#00FFC2] mb-1">
                  <span>ğŸ”¦ í”¼ë¶€ í‘œë©´ ìŠ¤ìº” ì¤‘</span>
                  <span className="font-bold">{Math.round(laserProgress)}%</span>
                </div>
                {/* ğŸš€ GPU ìµœì í™”: ì§„í–‰ ë°” (CSS transitionìœ¼ë¡œ width ë³€ê²½) */}
                <div className="w-52 h-3 bg-gray-800 rounded-full overflow-hidden mx-auto border border-[#00FFC2]/30">
                  <div 
                    className="h-full bg-gradient-to-r from-[#00FFC2] via-[#00E6B8] to-[#00FFC2] neon-glow-mint gpu-accelerated"
                    style={{
                      width: `${laserProgress}%`,
                      transition: 'width 0.1s linear',
                    }}
                  />
                </div>
              </div>
            )}
            {scanningStage === 'processing' && (
              <div className="mt-3">
                {/* ğŸš€ GPU ìµœì í™”: ë¡œë”© ì ë“¤ (CSS ì• ë‹ˆë©”ì´ì…˜) */}
                <div className="flex items-center justify-center gap-3">
                  <div className="w-3 h-3 bg-[#00FFC2] rounded-full neon-glow-mint animate-blink gpu-accelerated" />
                  <div className="w-3 h-3 bg-[#00FFC2] rounded-full neon-glow-mint animate-blink-delay-1 gpu-accelerated" />
                  <div className="w-3 h-3 bg-[#00FFC2] rounded-full neon-glow-mint animate-blink-delay-2 gpu-accelerated" />
                </div>
              </div>
            )}
          </div>

          {/* ğŸš€ GPU ìµœì í™”: ì˜¤í†  ìº¡ì²˜ ì§„í–‰ë¥  í‘œì‹œ */}
          {scanningStage === 'idle' && lockOnProgress > 0 && (
            <div className="flex items-center gap-3 mb-4 animate-fade-in">
              {/* ì§„í–‰ë¥  ë°” (CSS transition) */}
              <div className="flex-1 h-2 bg-gray-800 rounded-full overflow-hidden">
                <div
                  className="h-full bg-[#00FFC2] neon-glow-mint gpu-accelerated"
                  style={{ 
                    width: `${lockOnProgress}%`,
                    transition: 'width 0.1s linear',
                  }}
                />
              </div>
              {/* í¼ì„¼íŠ¸ í‘œì‹œ */}
              <span className="text-[#00FFC2] text-sm font-bold min-w-[3rem] text-right">
                {Math.round(lockOnProgress)}%
              </span>
            </div>
          )}

          {/* ìˆ˜ë™ ì´¬ì˜ ë³´ì¡° ë²„íŠ¼ (ì‘ê²Œ, ìš°ì¸¡ í•˜ë‹¨) */}
          {scanningStage === 'idle' && (
            <motion.div
              initial={{ opacity: 0 }}
              animate={{ opacity: 1 }}
              transition={{ delay: 1 }}
              className="flex items-center justify-center gap-4"
            >
              {/* ì•ˆë‚´ í…ìŠ¤íŠ¸ */}
              <p className="text-gray-500 text-xs">
                {lockOnProgress > 0 
                  ? 'ìë™ ì´¬ì˜ ì¤‘...' 
                  : 'ì–¼êµ´ì„ ë§ì¶”ë©´ ìë™ ì´¬ì˜ë©ë‹ˆë‹¤'}
              </p>
              
              {/* ìˆ˜ë™ ì´¬ì˜ ë²„íŠ¼ (ì‘ì€ ë³´ì¡° ë²„íŠ¼) */}
              <motion.button
                whileHover={{ scale: 1.1 }}
                whileTap={{ scale: 0.95 }}
                onClick={executeCinematicSequence}
                className="px-4 py-2 bg-gray-800/80 hover:bg-gray-700/80 text-gray-400 hover:text-white rounded-full text-xs font-medium transition-colors border border-gray-700"
              >
                ğŸ“· ìˆ˜ë™ ì´¬ì˜
              </motion.button>
            </motion.div>
          )}
        </div>
      )}

      {/* ì¹´ë©”ë¼ ë¡œë”© ìƒíƒœ */}
      {isCameraLoading && !cameraError && !isMockMode && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-900/90 backdrop-blur-sm z-10">
          <div className="text-center px-4">
            {/* ğŸš€ GPU ìµœì í™”: ìŠ¤í”¼ë„ˆ */}
            <div className="w-12 h-12 border-4 border-[#00FFC2] border-t-transparent rounded-full animate-gpu-spin mx-auto mb-4 gpu-accelerated" />
            <p className="text-white text-base font-medium mb-1">AI ì¹´ë©”ë¼ ì—°ê²° ì¤‘...</p>
            <p className="text-gray-400 text-xs">ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”</p>
          </div>
        </div>
      )}

      {/* ğŸš€ GPU ìµœì í™”: AR ëª¨ë¸ ë¡œë”© ìƒíƒœ */}
      {isCameraReady && !isModelReady && !cameraError && !isMockMode && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-900/80 backdrop-blur-sm z-10">
          <div className="text-center px-4">
            <div className="w-8 h-8 border-4 border-blue-500 border-t-transparent rounded-full animate-gpu-spin mx-auto mb-3 gpu-accelerated" />
            <p className="text-white text-sm font-medium mb-1">AR ëª¨ë¸ ë¡œë”© ì¤‘...</p>
            <p className="text-gray-400 text-xs">ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”</p>
          </div>
        </div>
      )}

      {/* ğŸš€ GPU ìµœì í™”: Mock Mode AR ëª¨ë¸ ë¡œë”© */}
      {isMockMode && !isModelReady && (
        <div className="absolute inset-0 flex items-center justify-center bg-black/30 backdrop-blur-sm z-10">
          <div className="text-center px-4">
            <div className="w-8 h-8 border-4 border-blue-500 border-t-transparent rounded-full animate-gpu-spin mx-auto mb-3 gpu-accelerated" />
            <p className="text-white text-sm font-medium mb-1">AR ëª¨ë¸ ë¡œë”© ì¤‘...</p>
            <p className="text-gray-400 text-xs">Mock Modeì—ì„œ ì‹¤í–‰ ì¤‘</p>
          </div>
        </div>
      )}

      {/* ì¹´ë©”ë¼ ì—ëŸ¬ ìƒíƒœ (Mock Modeê°€ ì•„ë‹ ë•Œë§Œ í‘œì‹œ) */}
      {cameraError && !isMockMode && (
        <div className="absolute inset-0 flex items-center justify-center bg-gray-900/95 backdrop-blur-sm z-10">
          <div className="text-center px-6 max-w-sm">
            <div className="w-16 h-16 bg-red-500/20 rounded-full flex items-center justify-center mx-auto mb-4">
              <svg className="w-8 h-8 text-red-500" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z" />
              </svg>
            </div>
            <p className="text-white text-base font-medium mb-2">ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨</p>
            <p className="text-gray-400 text-sm leading-relaxed mb-6">{cameraError}</p>
            <button
              onClick={handleRetry}
              className="px-6 py-3 bg-[#00FFC2] text-black font-semibold rounded-xl hover:bg-[#00E6B8] transition-colors"
            >
              ì¬ì‹œë„
            </button>
          </div>
        </div>
      )}
    </div>
  )
}


